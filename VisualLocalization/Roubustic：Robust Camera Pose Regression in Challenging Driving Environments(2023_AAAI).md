# Roubustic：Robust Camera Pose Regression in Challenging Driving Environments(2023_AAAI)



## Date:23.5.02-23.5.03



## Abstract

定位相机在已知场景的位置是很多应用的核心。那么在2D/3D的照片中去建立联系也是场景坐标回归以及特征匹配所作的工作。但是之前很多的工作都是在假定在静态环境下进行定位，那么在动态环境下的如果还使用这么方法显然是不可行的。在这篇文章中，作者主要采取了一个可以去剔除异常值的决策神经树将2D和3D之间的动态场景关联起来。其中主要有三个模块关键：

1. 分层次的空间分割：以此来决定神经树的形状。
2. 神经路由函数：文中说可以做到深度分类函数，以此做到更好的场景理解。
3. 异常值拒绝：将场景中的动态点在进行匹配的时候进行剔除。

提出的算法在TUM提出的RIO-10上进行了验证，达到SOTA。



## 1. Introduction

相机重定位的工作就是在已知环境中对相机进行6DOF分析。他对于很多计算机视觉以及机器人的应用有着很重要的作用（SLAM，AR，导航等等）。很多好的方法有基于激光雷达，WIFI，GPS以及雷达的。然而这些方法会受到信号，天气等的影响，那么RGB或者RGB-D的相机可以通过视觉重定位的方式来实现定位。

那么视觉重定位已经发展了很多年（最早我找到看的文章应该是11/12年），近期的工作已经可以实现室内环境7Scene达到100%Acc（5cm/5度）。一个典型的方法就是决策树以及后续的很多变种方法。从方法上来看，**他们建立了二进制回归森林，把查询图像中的点（特征点？）作为输入，然后通过层次划分策略（*简单实现查询点附近颜色以及深度的对比*）放到树的叶子节点中**。那么通过评估测试图片，就可以将2D-3D or 3D-3D的方法建立场景联系，为位姿优化做到场景坐标的世界坐标系的回归。

但是之前的很多方法都是建立在静态场景下进行视觉重定位，他们这种方法运用在动态场景下都失败了，对于动态场景下如何产生正确的环境匹配是至关重要的。

在这篇文章中，提出了异常值感知的神经树来帮助建立起正确的相机位子估计的特征匹配关系，其中这种关系只关注于有信心的静态环境区域。

1. 分层的空间划分：对于世界坐标的3D场景进行显式的分层空间划分以以此来构建决策树。分出来的空间不仅做到数据选择，还联系到了有实际物理意义的3S几何区域关联和划分。

2. 神经路由功能：给定了从图片采集到的特征点，分裂节点需要决定给子区域应该怎么划分，往哪里走。这么一个划分需要3D场景语义的理解。因此开发了神经路由函数来做到深度分类网络。

3. 异常值拒绝：为了解决潜在的动态输入点，则在分层路由的过程中把这些点当成异常点过滤。更加具体的来说，神经路由函数会去学输入点中的动态区域然后把他放到异常目录里面，停止更深层次的路由，一旦这个神经路由树徐练好了，就可以通过优化和细化来计算最后的位姿了。

   然后我们在RIO-10上进行了动态场景下的相机重定位，实验结果表明我们的算法超越了SOTA30%实现达到新SOTA





## 2. Related Work

### 2.1 Camera Relocalization

#### Direct pose estimation

这类的方法就是给一张图片直接给了相机位姿出来。一种主流的方法就是图片检索，他们会把相机位姿近似到数据库中和查询图片low-level feature最相近的图片的位姿上。PoseNet而是利用卷积神经网络直接回归6D相机位姿。然而，19年的Limits的文章中指出直接位姿回归和图片检索的性能以及原理最为接近。而且APR这种方法与Structed-based的方法相比，存在一定的差距。

#### Indirect pose estimation

这类的方法就是在相机和视觉坐标中建立关联，然后通过RANSAC优化来计算出相机位姿。一个普遍的方法就是利用传统关键点2D-3D的关联来计算位姿，而近期的方法都把特征提取用神经网络作为替代。另外一种方法就是场景坐标回归的方法，Shotten等人通过训练决策树从图片中的特征点回归到3D场景下的坐标点，当然也有用卷积神经网络来回归世界坐标系的。

### 2.2 Decision Tree and Deep Learning

当然也有把决策树和深度学习联系到一起的，深度神经决策树提出了一种联合全局的优化叶子和中间节点的方法。因此也可以做到端到端可微分的学习。Shen等人提出了标签分布学习树可以让所有的决策树在一个森林里面共同学习。深度神经决策树运用到了下游的单目深度估计的任务中。前面的大部分工作都是利用决策树表述分类神经网络的最后几个完全连接层，与我们的算法有很大不同。

## 3. Neural Routing

### 3.1 Overview

该算法的输入是由一系列的<RGB-D image, camera pose> 和测试图像输入来完成重定位，这个算法可以分为两大块：场景坐标关联以及相机位姿优化。第一步骤通过把特征点以及附近的语义信息作为输入学习神经树，然后回归3D-3D之间的场景关联，第二部分通过迭代ICP细化来迭代优化步骤。神经树通过显式空间划分来建立，在分层路由的过程中学习拒绝动态点（异常点）。从某种意义上，我们的算法建立起了（有信息状态下的静态场景区域）3D-3D的数据关联。

### 3.2 Decision Tree for Camera Localization

取决于目标是否连续还是离散，决策树的目标功能可以分为回归或者分类。对于一个决策树而言，其有中间节点和叶子节点，中间节点具有路由函数，每一个叶子节点具有适应于输入划分区域数据的概率密度分布。给定一个输入样本，推断从根结点开始进行。一个标准的决策树是二叉树，运用贪心算法来学到参数达到局部优化hard-data分区。

对于相机重定位而言，决策树被用来建立3D环境的先验知识，每一个中间节点会从相机图片选取想要的特征点，然后往下继续路由。叶子节点会找到一个适应了的3D点分布（从训练图片和校准参数映射过来）。因此当我们进行评估的时候，我们可以轻松建立3D-3D的数据关联。

### 3.3 Outlier-aware Neural Tree

#### 3.3.1 Hierarchical Space Partition for Decision

对于目前运用在视觉重定位而言，很多不是有标签的监督学习的。决策树最终会变成聚类算法。不同节点的决策规则通过CLUS算法学习，以方差约减为分割准则，实现局部最优的数据划分。在这篇论文中使用分层空间划分来重建决策树。**整个空间作为根结点，然后逐步迭代划分到预先设定的深度。每一个中间节点负责对应的一个子区域。然后在再该区域中等分小区域。每个叶子节点在其覆盖的局部几个区域会包含一组3D世界坐标。**

![image-20230409155636558](/home/benben/.config/Typora/typora-user-images/image-20230409155636558.png)

#### 3.3.2 Outlier-aware Neural Routing Function

对于给定输入,分裂节点路由函数的目的是把子点传递到树的孩子节点上去，在这个问题上给定的输入是2D（RGB-D frame?）,以及该点的真值标签（由周围的信息决定），为了实现准确预测，路由函数需要从2D观察中了解3D场景内容。受到的点云分类以及从图片中生成点云，我们利用了点云处理框架运用到了神经路由函数中

1. **Input representation** and sampling

   神经路由函数的输入是需要在3D世界下定位的图片点以及他周围的上下文信息。输入的点会有颜色和深度信息，但都两者高度依赖于viewpoint。为了获得在不同Viewpoint下的范化能力，通过**PPF-FoldNet可以增强他的深度通道**。首先利用相机标定参数将全帧深度投影到三维相机空间中，计算出oriented点云（什么点云？）还有17-point neighourhood中计算pointwise normal，然后将查询点和上下文信息编码成成对特征。

   

   总结来说，对于每一个点和上下文输入点，它包含颜色信息*c*以及旋转不变信息*r*，来表示7维信息。**由于所有上下文点的旋转不变特征是以查询点为原点的局部参考系中计算的，因此省略几何特征，仅将颜色作为附着点的输入。**

2. **Routing fuunction design**

   路由函数分为两部分：**特征提取模块以及分类模块**。特征提取模块利用（点态）MLP从查询点和上下文点中学习特征（具体可以看流行的点云处理网络PointNet），分类模块利用从查询点和上下文点的深度信息去学在树中应该往哪个子节点中去走。

3. Outlier rejection

   在测试帧中给定一个动态点，那么决策树会把他送到属于静止节点，这会建立不正确的3D-3D匹配。

   为了实现这个目标,我们进一步

#### 3.3.3 HyperNetwork for the Routing Functions



### Camera Pose Estimation







## 4. Experiment